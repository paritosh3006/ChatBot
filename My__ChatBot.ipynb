{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Sony\\Desktop\\Documents1.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0\n",
       "count         0.0\n",
       "mean          NaN\n",
       "std           NaN\n",
       "min           NaN\n",
       "25%           NaN\n",
       "50%           NaN\n",
       "75%           NaN\n",
       "max           NaN"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 9 columns):\n",
      "Unnamed: 0                      0 non-null float64\n",
      "question                        25 non-null object\n",
      "answer                          25 non-null object\n",
      "question_punctuation_removed    25 non-null object\n",
      "question_stopword_removed       25 non-null object\n",
      "question_negated                25 non-null object\n",
      "question_descriptive            25 non-null object\n",
      "question_stemmed                25 non-null object\n",
      "modified_sentence               25 non-null object\n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's explore our question set 0                        how are you doing today ?\n",
      "1                                how is your day ?\n",
      "2                                         good day\n",
      "3                                     good morning\n",
      "4     Hope you have a lovely and beautiful morning\n",
      "5                What a beautiful and pleasant day\n",
      "6                          Have a pleasant morning\n",
      "7                            what a lovely morning\n",
      "8                          how is it going today ?\n",
      "9                                  have a nice day\n",
      "10                                   see you later\n",
      "11                                      good night\n",
      "12                                         bye bye\n",
      "13                               talk to you later\n",
      "14                          see you sometime later\n",
      "15                                 have a nice day\n",
      "16                                talk to you soon\n",
      "17                              make me a sandwich\n",
      "18                      can you make a sandwitch ?\n",
      "19                      having a sandwitch today ?\n",
      "20                               what's for lunch?\n",
      "21                 I want to eat a sandwitch today\n",
      "22                 I do not want a sandwitch today\n",
      "23                             What is in the menu\n",
      "24                               What is for lunch\n",
      "Name: question, dtype: object\n",
      "Length of training set 25\n",
      "Unique answers are {'goodbye', 'sandwitch', 'greeting'}  and number of unique answers are  3\n"
     ]
    }
   ],
   "source": [
    "print (\"Let's explore our question set\",data[\"question\"])\n",
    "print (\"Length of training set\",len(data[\"question\"]))\n",
    "print (\"Unique answers are\",set(data[\"answer\"]),\" and number of unique answers are \", len(set(data[\"answer\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now let's create a wordcloud to get a better understanding of our corpus\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "##### Download using conda install -c conda-forge wordcloud\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(background_color='black',).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'are', 'you', 'doing', 'today', '?', 'how', 'is', 'your', 'day', '?', 'good', 'day', 'good', 'morning', 'Hope', 'you', 'have', 'a', 'lovely', 'and', 'beautiful', 'morning', 'What', 'a', 'beautiful', 'and', 'pleasant', 'day', 'Have', 'a', 'pleasant', 'morning', 'what', 'a', 'lovely', 'morning', 'how', 'is', 'it', 'going', 'today', '?', 'have', 'a', 'nice', 'day', 'see', 'you', 'later', 'good', 'night', 'bye', 'bye', 'talk', 'to', 'you', 'later', 'see', 'you', 'sometime', 'later', 'have', 'a', 'nice', 'day', 'talk', 'to', 'you', 'soon', 'make', 'me', 'a', 'sandwich', 'can', 'you', 'make', 'a', 'sandwitch', '?', 'having', 'a', 'sandwitch', 'today', '?', \"what's\", 'for', 'lunch?', 'I', 'want', 'to', 'eat', 'a', 'sandwitch', 'today', 'I', 'do', 'not', 'want', 'a', 'sandwitch', 'today', 'What', 'is', 'in', 'the', 'menu', 'What', 'is', 'for', 'lunch']\n"
     ]
    }
   ],
   "source": [
    "##### Let's change the list of questions into list of words for better visualization\n",
    "word_list=[]\n",
    "list_question=list(data[\"question\"])\n",
    "for sentence in list_question:\n",
    "\twords_sentence=sentence.split()\n",
    "\tfor words in words_sentence:\n",
    "\t\tword_list.append(words)\n",
    "\n",
    "\n",
    "word_list=[word for sentence in list(data[\"question\"]) for word in sentence.split()]\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'a': 11, 'you': 7, 'today': 5, '?': 5, 'day': 5, 'is': 4, 'morning': 4, 'sandwitch': 4, 'how': 3, 'good': 3, 'have': 3, 'What': 3, 'later': 3, 'to': 3, 'lovely': 2, 'and': 2, 'beautiful': 2, 'pleasant': 2, 'nice': 2, 'see': 2, 'bye': 2, 'talk': 2, 'make': 2, 'for': 2, 'I': 2, 'want': 2, 'are': 1, 'doing': 1, 'your': 1, 'Hope': 1, 'Have': 1, 'what': 1, 'it': 1, 'going': 1, 'night': 1, 'sometime': 1, 'soon': 1, 'me': 1, 'sandwich': 1, 'can': 1, 'having': 1, \"what's\": 1, 'lunch?': 1, 'eat': 1, 'do': 1, 'not': 1, 'in': 1, 'the': 1, 'menu': 1, 'lunch': 1})\n",
      "[('a', 11), ('you', 7), ('today', 5), ('?', 5), ('day', 5)]\n"
     ]
    }
   ],
   "source": [
    "##### Now let's find the frequency of each word and the most common words in the corpus\n",
    "frequency=Counter(word_list)\n",
    "print (frequency)\n",
    "print (frequency.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels,values = zip(*frequency.items())\n",
    "labels=[]\n",
    "values=[]\n",
    "for T in frequency.most_common(5):\n",
    "    labels.append(T[0])\n",
    "    values.append(T[1])\n",
    "\n",
    "indexes = np.arange(len(labels))\n",
    "width = 1\n",
    "\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes + width * 0.05, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         [how, are, you, doing, today]\n",
      "1                                  [how, is, your, day]\n",
      "2                                           [good, day]\n",
      "3                                       [good, morning]\n",
      "4     [hope, you, have, a, lovely, and, beautiful, m...\n",
      "5              [what, a, beautiful, and, pleasant, day]\n",
      "6                          [have, a, pleasant, morning]\n",
      "7                            [what, a, lovely, morning]\n",
      "8                           [how, is, it, going, today]\n",
      "9                                  [have, a, nice, day]\n",
      "10                                    [see, you, later]\n",
      "11                                        [good, night]\n",
      "12                                           [bye, bye]\n",
      "13                               [talk, to, you, later]\n",
      "14                          [see, you, sometime, later]\n",
      "15                                 [have, a, nice, day]\n",
      "16                                [talk, to, you, soon]\n",
      "17                              [make, me, a, sandwich]\n",
      "18                       [can, you, make, a, sandwitch]\n",
      "19                        [having, a, sandwitch, today]\n",
      "20                                  [whats, for, lunch]\n",
      "21              [i, want, to, eat, a, sandwitch, today]\n",
      "22              [i, do, not, want, a, sandwitch, today]\n",
      "23                            [what, is, in, the, menu]\n",
      "24                               [what, is, for, lunch]\n",
      "Name: question_punctuation_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Remove Punctuations and change words to lower case\n",
    "def remove_punctuations(text):    \n",
    "    words=[word.lower() for word in text.split()] \n",
    "    words=[w for word in words for w in re.sub(r'[^\\w\\s]','',word).split()]    \n",
    "    return words\n",
    "\n",
    "data[\"question_punctuation_removed\"]=data[\"question\"].apply(remove_punctuations)\n",
    "print (data[\"question_punctuation_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ourselves', \"you'll\", 'between', \"that'll\", 'below', 'their', 'your', 'will', 'didn', 'her', 'll', 'are', 'themselves', 'on', 'most', 'how', \"doesn't\", 'about', 'until', 'more', 'while', 'then', 'don', \"should've\", 'am', 'mustn', 'such', 'hasn', 'and', 'its', 'for', 'shan', 'over', 'isn', 'by', 'yourselves', 'few', 'myself', 'o', 'wasn', 'than', \"she's\", 'what', \"didn't\", 'were', 'to', \"you've\", 'is', \"wouldn't\", \"shouldn't\", 'who', 'a', 'into', 'down', 'too', 'but', 'haven', \"aren't\", 'against', 'yourself', 're', 'did', 'just', 'if', 'be', 'other', 'aren', 'have', 'these', 'own', \"hasn't\", 'mightn', 'won', 'does', 'above', 'do', 'we', 'weren', 'you', 'not', 'y', 'with', 'that', 'once', 'the', 'there', 'herself', 'had', 'itself', 'they', 'all', 'hers', 's', 'she', 'out', \"weren't\", \"you're\", 'me', \"wasn't\", 't', 'should', 'during', 'm', 'himself', 'at', 'again', 'in', \"you'd\", 'before', 'shouldn', 've', 'further', 'those', 'which', 'or', 'wouldn', \"haven't\", 'this', 'hadn', \"won't\", 'yours', 'he', 'after', 'off', \"shan't\", 'has', \"don't\", 'being', 'can', 'whom', 'his', 'theirs', 'each', 'been', 'some', 'here', 'i', 'from', 'any', 'my', 'having', 'an', 'why', 'under', 'nor', 'same', \"it's\", 'ain', 'of', \"isn't\", 'it', 'only', 'when', 'no', 'was', 'our', 'now', 'doesn', 'up', \"hadn't\", 'where', 'as', 'd', 'very', \"couldn't\", 'ours', 'so', 'needn', 'both', 'them', 'doing', 'through', 'couldn', 'ma', \"mustn't\", 'because', \"needn't\", 'him', \"mightn't\"}\n",
      "0                                [today]\n",
      "1                                  [day]\n",
      "2                            [good, day]\n",
      "3                        [good, morning]\n",
      "4     [hope, lovely, beautiful, morning]\n",
      "5             [beautiful, pleasant, day]\n",
      "6                    [pleasant, morning]\n",
      "7                      [lovely, morning]\n",
      "8                         [going, today]\n",
      "9                            [nice, day]\n",
      "10                          [see, later]\n",
      "11                         [good, night]\n",
      "12                            [bye, bye]\n",
      "13                         [talk, later]\n",
      "14                [see, sometime, later]\n",
      "15                           [nice, day]\n",
      "16                          [talk, soon]\n",
      "17                      [make, sandwich]\n",
      "18                     [make, sandwitch]\n",
      "19                    [sandwitch, today]\n",
      "20                        [whats, lunch]\n",
      "21         [want, eat, sandwitch, today]\n",
      "22              [want, sandwitch, today]\n",
      "23                                [menu]\n",
      "24                               [lunch]\n",
      "Name: question_stopword_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Remove StopWords\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "print (stop)\n",
    "def remove_stopwords(text):\n",
    "\tmodified_word_list=[word for word in text if word not in stop]\n",
    "\treturn modified_word_list\n",
    "\n",
    "data[\"question_stopword_removed\"]=data[\"question_punctuation_removed\"].apply(remove_stopwords)\n",
    "print (data[\"question_stopword_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         [how, are, you, doing, today]\n",
      "1                                  [how, is, your, day]\n",
      "2                                           [good, day]\n",
      "3                                       [good, morning]\n",
      "4     [hope, you, have, a, lovely, and, beautiful, m...\n",
      "5              [what, a, beautiful, and, pleasant, day]\n",
      "6                          [have, a, pleasant, morning]\n",
      "7                            [what, a, lovely, morning]\n",
      "8                           [how, is, it, going, today]\n",
      "9                                  [have, a, nice, day]\n",
      "10                                    [see, you, later]\n",
      "11                                        [good, night]\n",
      "12                                           [bye, bye]\n",
      "13                               [talk, to, you, later]\n",
      "14                          [see, you, sometime, later]\n",
      "15                                 [have, a, nice, day]\n",
      "16                                [talk, to, you, soon]\n",
      "17                              [make, me, a, sandwich]\n",
      "18                       [can, you, make, a, sandwitch]\n",
      "19                        [having, a, sandwitch, today]\n",
      "20                                  [whats, for, lunch]\n",
      "21              [i, want, to, eat, a, sandwitch, today]\n",
      "22               [i, do, not-want, a, sandwitch, today]\n",
      "23                            [what, is, in, the, menu]\n",
      "24                               [what, is, for, lunch]\n",
      "Name: question_negated, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def negation_handling(words):\n",
    "    counter=False    \n",
    "    wlist=[]    \n",
    "    negations=[\"no\",\"not\",\"cant\",\"cannot\",\"never\",\"less\",\"without\",\"barely\",\"hardly\",\"rarely\",\"no\",\"not\",\"noway\",\"didnt\"]\n",
    "    #for words in wordlist:       \n",
    "    for i,j in enumerate(words):                           \n",
    "            if j in negations and i<len(words)-1:             \n",
    "                wlist.append(str(words[i]+'-'+words[i+1]))\n",
    "                counter=True\n",
    "            else:\n",
    "                if counter is False:                \n",
    "                    wlist.append(words[i])\n",
    "                else:\n",
    "                    counter=False\n",
    "    return wlist\n",
    "\n",
    "data[\"question_negated\"]=data[\"question_punctuation_removed\"].apply(negation_handling)\n",
    "print (data[\"question_negated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          [are, doing, today]\n",
      "1                                        [day]\n",
      "2                                  [good, day]\n",
      "3                              [good, morning]\n",
      "4     [hope, have, lovely, beautiful, morning]\n",
      "5                   [beautiful, pleasant, day]\n",
      "6                    [have, pleasant, morning]\n",
      "7                            [lovely, morning]\n",
      "8                               [going, today]\n",
      "9                            [have, nice, day]\n",
      "10                                [see, later]\n",
      "11                               [good, night]\n",
      "12                                  [bye, bye]\n",
      "13                               [talk, later]\n",
      "14                      [see, sometime, later]\n",
      "15                           [have, nice, day]\n",
      "16                                [talk, soon]\n",
      "17                            [make, sandwich]\n",
      "18                           [make, sandwitch]\n",
      "19                  [having, sandwitch, today]\n",
      "20                                     [lunch]\n",
      "21            [i, want, eat, sandwitch, today]\n",
      "22            [do, not-want, sandwitch, today]\n",
      "23                                      [menu]\n",
      "24                                     [lunch]\n",
      "Name: question_descriptive, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "def descriptive_words(words):\n",
    "    meaningful_words=[]    \n",
    "    tags=['VB','VBP','VBD','VBG','VBN','JJ','JJR','JJS','RB','RBR','RBS','UH',\"NN\",'NNP']    \n",
    "    tagged_word=pos_tag(words)\n",
    "    for word in tagged_word:            \n",
    "        if word[1] in tags:\n",
    "            meaningful_words.append(word[0])\n",
    "    return meaningful_words \n",
    "data[\"question_descriptive\"]=data[\"question_negated\"].apply(descriptive_words)\n",
    "print (data[\"question_descriptive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     [are, do, today]\n",
      "1                                [day]\n",
      "2                          [good, day]\n",
      "3                         [good, morn]\n",
      "4     [hope, have, love, beauti, morn]\n",
      "5              [beauti, pleasant, day]\n",
      "6               [have, pleasant, morn]\n",
      "7                         [love, morn]\n",
      "8                          [go, today]\n",
      "9                    [have, nice, day]\n",
      "10                        [see, later]\n",
      "11                       [good, night]\n",
      "12                          [bye, bye]\n",
      "13                       [talk, later]\n",
      "14               [see, sometim, later]\n",
      "15                   [have, nice, day]\n",
      "16                        [talk, soon]\n",
      "17                    [make, sandwich]\n",
      "18                   [make, sandwitch]\n",
      "19            [have, sandwitch, today]\n",
      "20                             [lunch]\n",
      "21    [i, want, eat, sandwitch, today]\n",
      "22    [do, not-want, sandwitch, today]\n",
      "23                              [menu]\n",
      "24                             [lunch]\n",
      "Name: question_stemmed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Stemming of Words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "st=PorterStemmer()\n",
    "def Stemming(text):\n",
    "\tstemmed_words=[st.stem(word) for word in text] \n",
    "\treturn stemmed_words\n",
    "\n",
    "data[\"question_stemmed\"]=data[\"question_descriptive\"].apply(Stemming)\n",
    "print (data[\"question_stemmed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    are do today\n",
      "1                             day\n",
      "2                        good day\n",
      "3                       good morn\n",
      "4      hope have love beauti morn\n",
      "5             beauti pleasant day\n",
      "6              have pleasant morn\n",
      "7                       love morn\n",
      "8                        go today\n",
      "9                   have nice day\n",
      "10                      see later\n",
      "11                     good night\n",
      "12                        bye bye\n",
      "13                     talk later\n",
      "14              see sometim later\n",
      "15                  have nice day\n",
      "16                      talk soon\n",
      "17                  make sandwich\n",
      "18                 make sandwitch\n",
      "19           have sandwitch today\n",
      "20                          lunch\n",
      "21     i want eat sandwitch today\n",
      "22    do not-want sandwitch today\n",
      "23                           menu\n",
      "24                          lunch\n",
      "Name: modified_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Recreating the sentence\n",
    "def Recreate(text):\n",
    "\tword=\" \".join(text)\n",
    "\treturn word\n",
    "\n",
    "data[\"modified_sentence\"]=data[\"question_stemmed\"].apply(Recreate)\n",
    "print (data[\"modified_sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    are do today\n",
      "1                             day\n",
      "2                        good day\n",
      "3                       good morn\n",
      "4      hope have love beauti morn\n",
      "5             beauti pleasant day\n",
      "6              have pleasant morn\n",
      "7                       love morn\n",
      "8                        go today\n",
      "9                   have nice day\n",
      "10                      see later\n",
      "11                     good night\n",
      "12                        bye bye\n",
      "13                     talk later\n",
      "14              see sometim later\n",
      "15                  have nice day\n",
      "16                      talk soon\n",
      "17                  make sandwich\n",
      "18                 make sandwitch\n",
      "19           have sandwitch today\n",
      "20                          lunch\n",
      "21     i want eat sandwitch today\n",
      "22    do not-want sandwitch today\n",
      "23                           menu\n",
      "24                          lunch\n",
      "Name: modified_sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def Cleaning(text):\n",
    "    text_punctuation_removed=remove_punctuations(text)\n",
    "    #text_stopword_removed=remove_stopwords(text_punctuation_removed)\n",
    "    text_unnegated=negation_handling(text_punctuation_removed)\n",
    "    text_descriptive=descriptive_words(text_unnegated)\n",
    "    text_stemmed=Stemming(text_descriptive)\n",
    "    final_text=Recreate(text_stemmed)\n",
    "    return final_text\n",
    "data[\"modified_sentence\"]=data[\"question\"].apply(Cleaning)\n",
    "print (data[\"modified_sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "['and', 'are', 'beautiful', 'bye', 'can', 'day', 'do', 'doing', 'eat', 'for', 'going', 'good', 'have', 'having', 'hope', 'how', 'in', 'is', 'it', 'later', 'lovely', 'lunch', 'make', 'me', 'menu', 'morning', 'nice', 'night', 'not', 'pleasant', 'sandwich', 'sandwitch', 'see', 'sometime', 'soon', 'talk', 'the', 'to', 'today', 'want', 'what', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "### Let's change the sentence into a bag of word model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data[\"question\"]).toarray()\n",
    "print(X)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Extra Tf-idf transformation and DataPipelines\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "model = Pipeline([('vectoizer', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer())])\n",
    "\n",
    "X_train = model.fit_transform(data[\"modified_sentence\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66458888 0.         0.         0.         0.58900082 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.45978218 0.        ]\n",
      " [0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.65152087 0.         0.\n",
      "  0.         0.75863071 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.7350886  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.67797106 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.46700056 0.         0.         0.         0.\n",
      "  0.         0.         0.36454709 0.526932   0.         0.46700056\n",
      "  0.         0.         0.         0.39149588 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.61906061 0.         0.48324727 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.61906061 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.51336864 0.         0.         0.\n",
      "  0.         0.         0.         0.55131892 0.         0.\n",
      "  0.         0.65764739 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.76633858\n",
      "  0.         0.         0.         0.64243691 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.8223762  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5689441  0.        ]\n",
      " [0.         0.         0.         0.52406528 0.         0.\n",
      "  0.         0.         0.52406528 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67135025 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67261429 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.73999326 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.62733449 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.77874992\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67261429 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.73999326 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.51630369 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.56802428 0.64092037\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.52406528 0.         0.\n",
      "  0.         0.         0.52406528 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.67135025 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.74838416 0.66326552 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.66326552 0.         0.         0.         0.\n",
      "  0.         0.         0.74838416 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.76633858 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.64243691 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.56314012 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.60476971 0.         0.\n",
      "  0.         0.         0.56314012 0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.59590367\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.44273992 0.         0.\n",
      "  0.         0.         0.41226373 0.52812763]\n",
      " [0.         0.         0.         0.         0.46700056 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.526932   0.         0.         0.39149588 0.         0.\n",
      "  0.         0.         0.36454709 0.46700056]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data[\"answer\"]\n",
    "question=\"have a nice day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goodbye']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sony\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Sony\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### Let's create our first Classification model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression().fit(X_train, Y)\n",
    "\n",
    "P=model.transform([Cleaning(question)])\n",
    "predict1=clf1.predict(P)\n",
    "print (predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goodbye']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf2 = MultinomialNB().fit(X_train, Y)\n",
    "\n",
    "P=model.transform([Cleaning(question)])\n",
    "predict2=clf2.predict(P)\n",
    "print (predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['goodbye']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf3 = DecisionTreeClassifier().fit(X_train, Y)\n",
    "\n",
    "P=model.transform([Cleaning(question)])\n",
    "predict3=clf3.predict(P)\n",
    "print (predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pydotplus.graphviz.Dot object at 0x00000262E35627F0>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf3, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "print (graph)\n",
    "graph.write_pdf(\"iris.pdf\")\n",
    "from IPython.display import Image\n",
    "\n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus answer to your question is goodbye\n"
     ]
    }
   ],
   "source": [
    "final_predict=[]\n",
    "final_predict=list(predict1)+list(predict2)+list(predict3)\n",
    "final_predict = Counter(final_predict)\n",
    "print (\"Thus answer to your question is\",final_predict.most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(text):\n",
    "    P=model.transform([Cleaning(text)])\n",
    "    predict1=clf1.predict(P)\n",
    "    #print (predict1)\n",
    "\n",
    "    predict2=clf2.predict(P)\n",
    "    #print (predict2)\n",
    "    \n",
    "    predict3=clf3.predict(P)\n",
    "    #print (predict3)\n",
    "    \n",
    "    final_predict=[]\n",
    "    final_predict=list(predict1)+list(predict2)+list(predict3)\n",
    "    final_predict = Counter(final_predict)\n",
    "    print (\"Class of Question belongs to = \",final_predict.most_common(1)[0][0])\n",
    "    \n",
    "    return final_predict.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Finding the most similar sentence\n",
    "#from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "#cosine_similarities = linear_kernel(X_train[1], X_train).flatten()\n",
    "#print (\"Cosine Similarity of\",data[\"question\"][0],\"with all questions in Corpus\",cosine_similarities)\n",
    "#index=[i+1 for i in range(len(X))]\n",
    "#print (index)\n",
    "#print (\"top 3 most similar question's to\",data[\"question\"][0],\"are :\")\n",
    "#print (sorted(zip(cosine_similarities, index, data[\"question\"][index]), reverse=True)[:3])\n",
    "#print (\"Thus answer to your question is \", max(data[\"answer\"][index[0]],data[\"answer\"][index[1]],data[\"answer\"][index[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Generate Answers ######\n",
    "answer_dictionary={\"greeting\":[\"Have a happy day\",\"Good morning\",\"Have a pleasant day\",\"Good Day\"],\n",
    "                  \"sandwitch\":[\"What kind of Sandwitch do you like\",\"Sandwitches are great\",\"Sandwitches are delicious\",\"I love sandwitch too\"],\n",
    "                  \"goodbye\":[\"Goodbye\",\"Have a good day\",\"Was nice meeting you\",\"See you later\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_answer(predict_class):\n",
    "    ans=random.choice(answer_dictionary[predict_class])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Question =good day\n",
      "Class of Question belongs to =  greeting\n",
      "Answer =  Have a happy day\n"
     ]
    }
   ],
   "source": [
    "###### The ChatBot #######\n",
    "question = input(\"Enter Question =\")\n",
    "prediction=Predict(question)\n",
    "ans=generate_answer(prediction)\n",
    "print(\"Answer = \",ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of Question belongs to =  goodbye\n",
      "goodbye\n",
      "Class of Question belongs to =  sandwitch\n",
      "sandwitch\n",
      "Class of Question belongs to =  greeting\n",
      "greeting\n",
      "['goodbye', 'sandwitch', 'greeting']\n",
      "['greeting', 'sandwitch', 'greeting']\n",
      "[[0 0 0]\n",
      " [1 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "### Checking Accuracy of the Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(data[\"question\"], data[\"answer\"], random_state=0)\n",
    "\n",
    "X_test=[\"have a nice day\",\"what's for lunch\",\"how are you\"]\n",
    "Y_test=[\"greeting\",\"sandwitch\",\"greeting\"]\n",
    "\n",
    "Y_pred=[]\n",
    "for i in X_test:\n",
    "    prediction=Predict(i)\n",
    "    print(prediction)\n",
    "    Y_pred.append(prediction)\n",
    "print (Y_pred)\n",
    "print (Y_test)\n",
    "cnf_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "print (cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [1 1 0]\n",
      " [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"red\" if cm[i, j] > thresh else \"blue\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"+\",\"-\"],title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
